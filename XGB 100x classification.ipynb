{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6df156b5",
   "metadata": {},
   "source": [
    "## Import all necessary packages to notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab37448-650a-4c5d-91ea-262499127484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from IPython.display import clear_output\n",
    "##### basic tool bos for operation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b32e8-68e0-4484-994a-4841fa08205c",
   "metadata": {},
   "source": [
    "## Function to classify specified dataset, this is to run out-of -the sample classification aka Mouse wise classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf0eab-7e31-4436-970c-a94026bace56",
   "metadata": {},
   "source": [
    "The idea behind classification is to take out few mice data completly and train model with rest of the data. Once model is trained run validation using remaining data. The function iterates nreps times, randomly selecting n_test_samples samples for testing and the remaining for training. It then fits a LightGBM classifier to the training data and evaluates it on the test data. For each model iteration, it calculates various metrics such as accuracy, F1 score, AUC score, and SHAP values for both training and test data.\n",
    "\n",
    "The results are stored in a dictionary report_from_model, which contains DataFrames for AccuracyTrain, AccuracyTest, f1_class0, f1_class1, auc_Score, SHAP_train, and SHAP_test.\n",
    "\n",
    "This function is designed to provide insights into model performance and feature importance for the given classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "717c88d2-9f81-4b13-9318-b3cdeec33639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification(nreps, MouseList, n_test_samples, metaCol, clss_col_name,  top5_parameters, df_to_class = None):\n",
    "    \"\"\"This function is designed to run classification takes below arguements\n",
    "    nreps = Number of repetition to run example it randomly samples the...\n",
    "            data again and again runs the classification for nreps (for ms it is 100)\n",
    "    MouseList = A list of mice list in data set, which can also used....\n",
    "                to filter out data form mouse which need to be excluded (simply not left out from the list will be excluded)\n",
    "    n_test_samples = Number to specify the test (validation) data size\n",
    "    df_tim_filt = df frame which contains the data 2D (n_trials and n_mice X freatures and metacolumns) \n",
    "    metaCol = Column names which contains meta information about data such has miceID, time_intervals, drugID,..etc\n",
    "    clss_col_name = cloumn name which has class ID (it could be drug name or drug ID in this case)\n",
    "    top5_parameters = A dictionary has top 5 model parameters                \n",
    "    \"\"\"\n",
    "    report_from_model = {\n",
    "        'AccuracyTrain': pd.DataFrame(),\n",
    "        'AccuracyTest' : pd.DataFrame(),\n",
    "        'f1_class0'    : pd.DataFrame(),\n",
    "        'f1_class1'    : pd.DataFrame(),\n",
    "        'auc_Score'    : pd.DataFrame(),\n",
    "        'SHAP_train'   : pd.DataFrame(),\n",
    "        'SHAP_test'    : pd.DataFrame()}\n",
    "    \n",
    "    ## Iteration n repetition\n",
    "    for idx in range(0, nreps):\n",
    "        \n",
    "        testList  = random.sample(MouseList, n_test_samples)\n",
    "        trainList = [i for i in MouseList if i not in testList] ## collect data which is not in test list\n",
    "        testList.sort()\n",
    "        trainList.sort()\n",
    "   \n",
    "        ### Select desired TimBins only \n",
    "        df_train = df_to_class[df_to_class['MouseID'].isin(trainList)]                \n",
    "        df_test  = df_to_class[df_to_class['MouseID'].isin(testList)]\n",
    "        \n",
    "        X_train = df_train.drop(metaCol, axis = 1)\n",
    "        X_test  = df_test.drop(metaCol, axis = 1)\n",
    "    \n",
    "        label_encoder = LabelEncoder()\n",
    "        y_train = pd.Series(label_encoder.fit_transform(df_train['DrugID']))\n",
    "        y_test  = pd.Series(label_encoder.fit_transform(df_test['DrugID']))\n",
    "   \n",
    "        print('Training data class counts is ', y_train.value_counts())\n",
    "        print('Test data class counts is ',y_test.value_counts())\n",
    "    \n",
    "        ## Iteration through top 5 models\n",
    "        for ModIdx, modelName in enumerate(modelList):\n",
    "            optim_parms = top5_parameters[str(ModIdx)]    \n",
    "            model = XGBClassifier(**{**basic_params,**optim_parms})                          \n",
    "               \n",
    "            print('computing Classififcation for -', '--model-', modelName, ' repetition-', str(idx))\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            ### Get the model trained accurac \n",
    "            \"\"\"It is not used in general just to cross check the trained accuracy with test accuracy\n",
    "            if train accuracy is too different than test accuracy the the model is not performing good\"\"\"                \n",
    "            y_train_pred = model.predict(X_train)\n",
    "            ### Calculate the training accuracy\n",
    "            train_accuracy = accuracy_score(y_train, y_train_pred)                \n",
    "            report_from_model['AccuracyTrain'].loc[idx, modelName] = train_accuracy;                \n",
    "          \n",
    "            ### Get SHAP values for Train data                \n",
    "            explainer_train  = shap.TreeExplainer(model)\n",
    "            shap_values_test = explainer_train(X_test)                \n",
    "            vals_test        = shap_values_test.values                \n",
    "            vals_test_abs    = np.abs(vals_test)\n",
    "            val_test_mean    = np.mean(vals_test_abs, axis=0) \n",
    "            temp_shap = pd.DataFrame(val_test_mean)\n",
    "                \n",
    "            temp_shap.columns = [modelName]                \n",
    "            report_from_model['SHAP_train'] = pd.concat([report_from_model['SHAP_train'], temp_shap.T], axis = 0);\n",
    "                        \n",
    "            \"\"\"-------------------------------------------------------------------------------------\"\"\"            \n",
    "            ### Predict test data set using trained model \n",
    "            \"\"\"this is important step in the classification\"\"\" \n",
    "            y_pred = model.predict(X_test)                  \n",
    "   \n",
    "            ### Get SHAP values for Test data\n",
    "            explainer_test   = shap.TreeExplainer(model)\n",
    "            shap_values_test = explainer_test(X_test, y_test)                \n",
    "            vals_test        = shap_values_test.values                \n",
    "            vals_test_abs    = np.abs(vals_test)\n",
    "            val_test_mean    = np.mean(vals_test_abs, axis=0)        \n",
    "            temp_shap = pd.DataFrame(val_test_mean)\n",
    "            temp_shap.columns = [modelName]                \n",
    "            report_from_model['SHAP_test'] = pd.concat([report_from_model['SHAP_test'], temp_shap.T], axis = 0);   \n",
    "          \n",
    "            ### Calculate Area under the curve\n",
    "            auc = roc_auc_score(y_test, y_pred)\n",
    "            report_from_model['auc_Score'].loc[idx, modelName] = auc;                \n",
    "                           \n",
    "            ### Calculate the accuracy score add to loop list\n",
    "            Accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "            report_from_model['AccuracyTest'].loc[idx, modelName] = Accuracy;           \n",
    "            \n",
    "            ### Calculate F1 score and add to data stracture\n",
    "            class_report= classification_report(y_test, y_pred, target_names=[0,1],\n",
    "                                                output_dict=True,  zero_division=0)                \n",
    "            F1ScoreList  = pd.DataFrame(class_report).transpose()['f1-score']\n",
    "            \n",
    "            report_from_model['f1_class0'].loc[idx, modelName] = F1ScoreList[0];\n",
    "            report_from_model['f1_class1'].loc[idx, modelName] = F1ScoreList[1];            \n",
    "            \"\"\"-------------end of model loop--------------------------------------- \"\"\"   \n",
    "    \n",
    "    return report_from_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47a8a8-1042-4b0f-b79d-7037f7ebd20e",
   "metadata": {},
   "source": [
    "## Load Connectivity or PSD data and parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6403b3-c707-4627-aae0-6b38619cc72a",
   "metadata": {},
   "source": [
    "This snippet loads an Excel file located at the specified path (ExcelPath) with the given name (ExcelName). It reads the data from a specific sheet (sheet_name) within the Excel file into a pandas DataFrame (df).\n",
    "\n",
    "Additionally, it loads top 5 parameters for LightGBM (LGBM) models from a JSON file located at parms_dict_path with the name params_file_name. These parameters are stored in a dictionary called params_dict.\n",
    "\n",
    "The basic_params dictionary contains basic parameters for the LGBM models, such as objective, metric, boosting type, and verbosity.\n",
    "\n",
    "The modelList is a list of model names used for classification. In this case, it seems to contain 'LG1', 'LG2', 'LG3', 'LG4', and 'LG5'.\n",
    "\n",
    "This script snippet seems to be a part of a larger analysis or modeling process involving the classification of connectivity data using LGBM models, with parameters stored in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f92d8ba-ffbd-41da-bfe9-dd82582a787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###Connectivity Files info and get all sheet in excel\n",
    "ExcelPath = os.getcwd()\n",
    "ExcelName = 'SIFT connectivity data with final exclusion.xlsx'\n",
    "sheet_name = 'GGC_PreInjBaseline'\n",
    "df = pd.read_excel(os.path.join(ExcelPath, ExcelName), sheet_name = sheet_name)\n",
    "###------------------------------------------------------------------\n",
    "\n",
    "### Information and Read the top5 parameters JSON\n",
    "parms_dict_path = os.getcwd()\n",
    "params_file_name = 'Top5 parameters for XGB SIFT freq-subspace optuna results for GGC_PreInjBaseline.json'\n",
    "\n",
    "with open(os.path.join(parms_dict_path,params_file_name), \"r\") as json_file:\n",
    "    params_dict = json.load(json_file)\n",
    "###------------------------------------------------------------------\n",
    "\n",
    "basic_params = {'objective': 'binary:logistic',\n",
    "                'metric': 'binary_logloss',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'verbosity': 0,\n",
    "                'n_jobs' : -1,  \n",
    "                'tree_method': 'gpu_hist' ,\n",
    "                'seed':42}\n",
    "\n",
    "modelList = ['XG1',             \n",
    "             'XG2',\n",
    "             'XG3',\n",
    "             'XG4',\n",
    "             'XG5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea558087-3b0a-4a13-9983-fac0899d4c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5c9f38-d585-4b3b-9692-1f086200d448",
   "metadata": {},
   "source": [
    "This cell initializes several variables, including dictionaries to store classification results. It sets up experimental parameters such as the number of repetitions, whether to consider frequency subspaces, class column name, number of test samples, and defines drug IDs and combinations.\n",
    "\n",
    "The script creates intervals based on experimental durations and trial durations. It then iterates over drug combinations and time intervals, filtering the data accordingly. Within each iteration, it runs classification models, storing results in dictionaries for each time interval and frequency band.\n",
    "\n",
    "Finally, it aggregates results into dictionaries organized by drug combinations:\n",
    "\n",
    "Experimental parameters are initialized.\n",
    "Intervals are created based on experimental durations.\n",
    "The script iterates over drug combinations and time intervals.\n",
    "Classification models are run and results stored in dictionaries.\n",
    "Results are aggregated into dictionaries organized by drug combinations.\n",
    "Overall, this script is designed to analyze and classify data based on drug combinations and time intervals, storing the results for further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eedb8971-c449-4792-9bb7-212c3d8dd64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nreps = 100;\n",
    "FeqSubSpace = True\n",
    "clss_col_name = 'DrugID'\n",
    "n_test_samples = 2\n",
    "freqBands = ['Delta', 'Theta', 'Beta', 'LoGamma', 'MidGamma', 'HiGamma']\n",
    "metaCol = ['times','MouseID','ExptDay','DrugID', 'DrugName']\n",
    "feature_columns = [col for col in df.columns if col not in metaCol]\n",
    "\n",
    "DrugIds = {1:'Sal',\n",
    "           2:'SalT',\n",
    "           3:'Amph',\n",
    "           4:'Raclo',\n",
    "           5:'SCH',\n",
    "           6:'CLZ1',\n",
    "           7:'CLZ3'}\n",
    "\n",
    "if FeqSubSpace and freqBands:    \n",
    "    drg_combinations = {'Amph' :['Amph','Sal'],                   \n",
    "                        'Raclo':['Raclo','SalT'],\n",
    "                        'SCH'  :['SCH', 'Sal'],\n",
    "                        'CLZ1' :['CLZ1','Sal'],\n",
    "                        'CLZ3' :['CLZ3','Sal']}\n",
    "else:\n",
    "    drg_combinations = {'Amph' :['Amph','Sal'],                   \n",
    "                        'Raclo':['Raclo','SalT'],\n",
    "                        'SCH'  :['SCH', 'Sal'],\n",
    "                        'CLZ1' :['CLZ1','Sal'],\n",
    "                        'CLZ3' :['CLZ3','Sal'],\n",
    "                        'Sal'  :['SalT','Sal']}\n",
    "    \n",
    "interval_bin_dur = 10 ## Mins\n",
    "total_expt_dur   = 60 ## Mins\n",
    "trial_dur = 20 ## Secs\n",
    "time_index1 = list(range(interval_bin_dur, total_expt_dur+1, interval_bin_dur))\n",
    "time_index2 = list(range(trial_dur, (total_expt_dur*total_expt_dur)+1, trial_dur))\n",
    "    \n",
    "final_intervals = {}\n",
    "for idx, x in enumerate(time_index1):\n",
    "    key = f'{x}_min'\n",
    "    \"\"\"The value 30 is number obtained as 20s intervals for 10 mins i.e. give 30 trials \"\"\"\n",
    "    value = time_index2[idx * 30 : (idx + 1) * 30]  # Get the slice of time_index2\n",
    "    final_intervals[key] = value\n",
    "\n",
    "AccuracyTrain = {};\n",
    "AccuracyTest  = {};\n",
    "F1_class0     = {};\n",
    "F1_class1     = {};\n",
    "AUCScore      = {};\n",
    "SHAP_train    = {};\n",
    "SHAP_test     = {};\n",
    "\n",
    "for drg_cmb in drg_combinations.keys():\n",
    "\n",
    "    ## Final Mouse List\n",
    "    ## for Amphetamine 518 and 587 mouse excluded because of LMA\n",
    "    if 'Amph' in drg_cmb:\n",
    "        MouseList = [530, 574, 591, 303, 304, 305, 336, 340]\n",
    "        print(MouseList)\n",
    "    else:\n",
    "        MouseList = [530, 574, 591, 518, 587, 303, 304, 305, 336, 340]\n",
    "        print(MouseList)\n",
    " \n",
    "    ## Get the data for specific drug combination        \n",
    "    df_drg_filt = df[df['DrugName'].isin(drg_combinations[drg_cmb])]\n",
    "     \n",
    "    ### Get TimBin list   \n",
    "    TimBinAccuracyTrain = {};\n",
    "    TimBinAccuracyTest  = {};\n",
    "    TimBinF1_class0  = {};\n",
    "    TimBinF1_class0  = {};\n",
    "    TimBinAUCScore   = {};\n",
    "    TimBinSHAP_train = {};\n",
    "    TimBinSHAP_test  = {};\n",
    "    TimBin_mouse_List= {};\n",
    "\n",
    "    # Initialize dictionaries with empty dictionaries for each TimBin key\n",
    "    TimBinAccuracyTrain = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinAccuracyTest = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinF1_class0 = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinF1_class1 = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinAUCScore = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinSHAP_train = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    TimBinSHAP_test = {TimBin: {} for TimBin in final_intervals.keys()}\n",
    "    \n",
    "    for int_Idx, TimBin in enumerate(final_intervals):   \n",
    "        ## Get the data for specific time interval\n",
    "        df_tim_filt = df_drg_filt[df_drg_filt['times'].isin(final_intervals[TimBin])]\n",
    "       \n",
    "        if FeqSubSpace and freqBands: \n",
    "            for freq in freqBands :\n",
    "                ## clear the notebook cell ouput (helps to reduce workload)\n",
    "                clear_output(wait=False)\n",
    "                drg_cmb_name = f'{drg_combinations[drg_cmb][0]} vs {drg_combinations[drg_cmb][1]}' \n",
    "                top5_parameters = params_dict[f'{drg_cmb_name}_{freq}'] \n",
    "\n",
    "                ##get a list of all col names which contains specified freq-band name\n",
    "                freq_col = [col for col in df_drg_filt.columns if f'_{freq}' in col]\n",
    "            \n",
    "                filtered_col = metaCol + freq_col ### Combine meta column and freq-specific list\n",
    "                df_freq_filt = df_tim_filt[filtered_col] ### Filter the data to get only specific freqband data \n",
    "                              \n",
    "                report_from_model = run_classification(nreps, MouseList, n_test_samples, metaCol,\n",
    "                                                       clss_col_name, top5_parameters, df_to_class = df_freq_filt)\n",
    "                ### TimBins Loop    \n",
    "                TimBinAccuracyTrain[TimBin][freq] =  report_from_model['AccuracyTrain'];\n",
    "                TimBinAccuracyTest[TimBin][freq]  =  report_from_model['AccuracyTest'];   \n",
    "                TimBinF1_class0[TimBin][freq]  =  report_from_model['f1_class0'];\n",
    "                TimBinF1_class0[TimBin][freq]  =  report_from_model['f1_class1'];\n",
    "                TimBinAUCScore[TimBin][freq]   =  report_from_model['auc_Score'];\n",
    "                TimBinSHAP_train[TimBin][freq] =  report_from_model['SHAP_train'];\n",
    "                TimBinSHAP_test[TimBin][freq]  =  report_from_model['SHAP_test'];\n",
    "        \n",
    "        elif FeqSubSpace and not freqBands:\n",
    "            print('There is no frq band list or list is empty check the list and run cell again')\n",
    "\n",
    "        else:\n",
    "            ## clear the notebook cell ouput (helps to reduce workload)\n",
    "            clear_output(wait=False)\n",
    "            drg_cmb_name = f'{drg_combinations[drg_cmb][0]} vs {drg_combinations[drg_cmb][1]}' \n",
    "            top5_parameters = params_dict[drg_cmb_name]           \n",
    "            report_from_model = run_classification(nreps, MouseList, n_test_samples, metaCol,\n",
    "                                                       clss_col_name, top5_parameters, df_to_class = df_tim_filt)\n",
    "\n",
    "            ### TimBins Loop    \n",
    "            TimBinAccuracyTrain[TimBin]['all'] =  report_from_model['AccuracyTrain'];\n",
    "            TimBinAccuracyTest[TimBin]['all']  =  report_from_model['AccuracyTest'];   \n",
    "            TimBinF1_class0[TimBin]['all']  =  report_from_model['f1_class0'];\n",
    "            TimBinF1_class0[TimBin]['all']  =  report_from_model['f1_class1'];\n",
    "            TimBinAUCScore[TimBin]['all']   =  report_from_model['auc_Score'];\n",
    "            TimBinSHAP_train[TimBin]['all'] =  report_from_model['SHAP_train'];\n",
    "            TimBinSHAP_test[TimBin]['all']  =  report_from_model['SHAP_test'];\n",
    "     \n",
    "    \"\"\"-------------------end of TimBins loop-------------------------------------\"\"\"\n",
    "    AccuracyTrain[drg_cmb_name] = TimBinAccuracyTrain\n",
    "    AccuracyTest[drg_cmb_name]  = TimBinAccuracyTest\n",
    "    F1_class0[drg_cmb_name]     = TimBinF1_class0\n",
    "    F1_class1[drg_cmb_name]     = TimBinF1_class0\n",
    "    AUCScore[drg_cmb_name]      = TimBinAUCScore\n",
    "    SHAP_train[drg_cmb_name]    = TimBinSHAP_train\n",
    "    SHAP_test[drg_cmb_name]     = TimBinSHAP_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52491f-eb34-4e75-a19b-da20fd352f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "455b78e7-4368-4a62-bd8a-c144286549a3",
   "metadata": {},
   "source": [
    "## Save the Result from classification as pkl for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885c4e00-4ef9-4b4f-9c75-95f8fd9c4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_together = {\n",
    "    'WT_AccuracyTrain':AccuracyTrain,\n",
    "    'WT_AccuracyTest' : AccuracyTest,\n",
    "    'WT_F1_class0'    : F1_class0,\n",
    "    'WT_F1_class1'    : F1_class1,\n",
    "    'WT_AUCScore'     : AUCScore,\n",
    "    'WT_SHAP_train'   : SHAP_train,\n",
    "    'WT_SHAP_test'    : SHAP_test,    \n",
    "    'params_dict'      : params_dict,\n",
    "    'basic_params'     : basic_params,\n",
    "    'final_intervals'  : final_intervals,\n",
    "    'DrugIds'          : DrugIds,\n",
    "    'drg_combinations' : drg_combinations,      \n",
    "    'freqBands'        : freqBands,\n",
    "    'FeqSubSpace'      : True\n",
    "}\n",
    "\n",
    "import pickle\n",
    "if FeqSubSpace:\n",
    "    pkl_name = 'Freq subspace'\n",
    "else:\n",
    "    pkl_name = 'all freq together'\n",
    "    \n",
    "with open(f'{sheet_name} {pkl_name} XGB 100x Classification.pkl', 'wb') as file:\n",
    "    pickle.dump(all_results_together, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173dc78a-283c-44f6-8e8e-bcd8f288ef13",
   "metadata": {},
   "source": [
    "## Plot and save the accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca966a88-9ebd-4cb6-a32e-71319e8bfd21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_accuracy(plt_accuracy_df,x, y, hue, legend_title, fig_ttl, xticklabels = None, \n",
    "                  figsize=(3, 2), palette=['mediumblue', 'magenta', 'darkorange', 'green', 'darkcyan', 'grey'],\n",
    "                  errorbar='se', err_style='bars', err_kws={'capsize':2, 'elinewidth' : 1, 'capthick':1},\n",
    "                  TickLabsize = 8 , textSize = 9, save_fig = False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        plt_accuracy_df (DataFrame): The DataFrame containing accuracy data.\n",
    "        x (str): The column name for the x-axis data.\n",
    "        y (str): The column name for the y-axis data.\n",
    "        hue (str): The column name to map plot aspects to different colors.\n",
    "        legend_title (str): The title for the legend.\n",
    "        fig_ttl (str): The title for the figure.\n",
    "        xticklabels (list, optional): Custom labels for x-axis ticks. Default is ['-10', '10', '20', '30', '40', '50'].\n",
    "        figsize (tuple, optional): Figure size (width, height) in inches. Default is (3, 2).\n",
    "        palette (list, optional): Color palette for the plot. Default is ['mediumblue', 'magenta', 'darkorange', 'green', 'darkcyan', 'grey'].\n",
    "        errorbar (str, optional): Method to draw error bars. Default is 'se'.\n",
    "        err_style (str, optional): Style of error bars. Default is 'bars'.\n",
    "        err_kws (dict, optional): Additional parameters for error bars. Default is {'capsize':2, 'elinewidth' : 1, 'capthick':1}.\n",
    "        TickLabsize (int, optional): Font size for tick labels. Default is 8.\n",
    "        textSize (int, optional): Font size for text elements. Default is 9.\n",
    "        save_fig (bool, optional): Whether to save the figure as a PDF and JPEG file. Default is False.\n",
    "\n",
    "        Example Usage:\n",
    "        \n",
    "        plot_accuracy(plt_accuracy_df, x='tbin', y='TestAccuracy', hue='freqBand',\n",
    "              legend_title='Frequency', fig_ttl='Accuracy Plot', save_fig=True)\n",
    "    \"\"\"\n",
    "\n",
    "    if xticklabels is None:\n",
    "        xticklabels = ['-10','10','20','30','40','50']        \n",
    "        \n",
    "    fig, axs = plt.subplots(ncols=1, sharex=False, sharey=False,\n",
    "                             constrained_layout=False, figsize=figsize)\n",
    "    \n",
    "    ax1 = sns.lineplot(ax = axs, x=x, y=y, hue=hue, data=plt_accuracy_df,\n",
    "                        palette = palette, errorbar =  errorbar, err_style=err_style, err_kws=err_kws)\n",
    "    ax1.axhline(y=0.5, linewidth=0.5, color=\"red\", dashes=[10, 8])\n",
    "    # Create a legend with handles and labels and place it outside the plot\n",
    "    ax1.legend(title=legend_title, bbox_to_anchor=(1.05, 1), loc='upper left',  frameon=False)\n",
    "    ax1.set_xticklabels(xticklabels, rotation=0, horizontalalignment='center', fontsize = 9)\n",
    "\n",
    "    # Additional customization for ax1\n",
    "    for line in ax1.lines:\n",
    "        line.set_linewidth(1)\n",
    "\n",
    "    ax1.tick_params(direction='out', length=4, width=0.5, colors='k', grid_color='k', grid_alpha=1, pad=0.3)\n",
    "    \n",
    "    ax1.spines[['right', 'top']].set_visible(False)\n",
    "    ax1.set_title(fig_ttl, size=textSize)\n",
    "    \n",
    "    ax1.set_ylabel('Mean\\nprediction accuracy', fontsize=textSize)\n",
    "    ax1.set_xlabel('Time(min)', fontsize=textSize)\n",
    "    ax1.set_ylim([0.4, 1])\n",
    "    ax1.tick_params(axis='x', which='major', pad=3, labelsize=TickLabsize)\n",
    "    ax1.tick_params(axis='y', which='major', pad=3, labelsize=TickLabsize)\n",
    " \n",
    "    figName = f' {fig_ttl}_100X accuracy.pdf' \n",
    "    figName2 = f' {fig_ttl}_100X accuracy.jpg' \n",
    "    \n",
    "    if save_fig:\n",
    "        plt.rcParams['pdf.use14corefonts'] = True\n",
    "        plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "        plt.savefig(figName,  dpi = 300, bbox_inches='tight', transparent=True, metadata={'Creator': None})\n",
    "        plt.savefig(figName2,  dpi = 300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "###---------------------------------- Plot the accuracy results ------------------------------------------------\n",
    "\n",
    "# Initialize an empty DataFrame to store final accuracy data\n",
    "final_accuracy = pd.DataFrame()\n",
    "\n",
    "# Iterate through each drug combination in the AccuracyTest dictionary\n",
    "for DrgCmb in AccuracyTest.keys():\n",
    "    # Initialize an empty DataFrame to store frequency bin data\n",
    "    fbin_df = pd.DataFrame()\n",
    "    # Iterate through each frequency in the first drug combination\n",
    "    for freq in AccuracyTest[DrgCmb][list(AccuracyTest[DrgCmb].keys())[0]].keys():\n",
    "        # Initialize an empty DataFrame to store time bin data\n",
    "        tbin_df = pd.DataFrame()\n",
    "        # Iterate through each time bin in the current drug combination\n",
    "        for tbin in AccuracyTest[DrgCmb].keys():\n",
    "            # Calculate the mean accuracy for the current frequency and time bin\n",
    "            tbin_df[tbin] = AccuracyTest[DrgCmb][tbin][freq].mean(axis=1)\n",
    "        # Add a column 'freqBand' with the current frequency to the time bin DataFrame\n",
    "        tbin_df['freqBand'] = freq\n",
    "        # Concatenate the time bin DataFrame with the frequency bin DataFrame\n",
    "        fbin_df = pd.concat([fbin_df, tbin_df], axis=0)\n",
    "    # Add a column 'DrgCmb' with the current drug combination to the frequency bin DataFrame\n",
    "    fbin_df['DrgCmb'] = DrgCmb\n",
    "    # Concatenate the frequency bin DataFrame with the final accuracy DataFrame\n",
    "    final_accuracy = pd.concat([final_accuracy, fbin_df], axis=0)\n",
    "\n",
    "# Melt the final accuracy DataFrame to long format\n",
    "plt_accuracy_df = final_accuracy.melt(id_vars=['freqBand', 'DrgCmb'], var_name='tbin', value_name='TestAccuracy')\n",
    "\n",
    "# Set save_fig to True\n",
    "save_fig = True\n",
    "\n",
    "# Check if there is only one frequency band\n",
    "if plt_accuracy_df['freqBand'].unique().shape[0] == 1:\n",
    "    # If only one frequency band, set legend_title and fig_ttl accordingly\n",
    "    legend_title = 'Drug vs veh'\n",
    "    fig_ttl = f'{sheet_name} accuracy'\n",
    "    # Plot accuracy using the plot_accuracy function\n",
    "    plot_accuracy(plt_accuracy_df, x='tbin', y='TestAccuracy', hue='DrgCmb',\n",
    "                  legend_title=legend_title, fig_ttl=fig_ttl, save_fig=save_fig)\n",
    "else:\n",
    "    # If multiple frequency bands, iterate through unique drug combinations\n",
    "    for plts in plt_accuracy_df['DrgCmb'].unique():\n",
    "        # Set legend_title and fig_ttl accordingly for each drug combination\n",
    "        legend_title = 'Frequency'\n",
    "        fig_ttl = f'{plts} {sheet_name} accuracy'\n",
    "        # Filter DataFrame for the current drug combination\n",
    "        filt_df = plt_accuracy_df[plt_accuracy_df['DrgCmb'].isin([plts])]\n",
    "        # Plot accuracy using the plot_accuracy function\n",
    "        plot_accuracy(filt_df, x='tbin', y='TestAccuracy', hue='freqBand',\n",
    "                      legend_title=legend_title, fig_ttl=fig_ttl, save_fig=save_fig)\n",
    "\n",
    "final_accuracy.to_excel(f'{fig_ttl}.xlsx', index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b57e5-55af-4c79-be36-cd0898dfae6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69dec92c-d98d-464e-b824-8a3102c4454c",
   "metadata": {},
   "source": [
    "## Plot and save the SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8e70b9-05cc-4f73-a019-85ec3a477472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "#### Get feature columns excluding meta columns from the DataFrame\n",
    "feature_columns = [col for col in df_tim_filt.columns if col not in metaCol]\n",
    "\n",
    "# Initialize a dictionary to store segmented features for each frequency band\n",
    "dict_seg_features = {}\n",
    "for freq in freqBands:\n",
    "    dict_seg_features[freq] = [fb for fb in df_drg_filt.columns if f'_{freq}' in fb]\n",
    "\n",
    "# Initialize a DataFrame to store averaged accuracy\n",
    "averaged_accu = pd.DataFrame(plt_accuracy_df.groupby(['freqBand', 'DrgCmb', 'tbin']).mean().to_records())\n",
    "averaged_accu['TestAccuracy'] = averaged_accu['TestAccuracy'] - 0.5\n",
    "\n",
    "# Set normalization flag\n",
    "normalize_to_accu = True\n",
    "norm_test_shap = {}\n",
    "\n",
    "mask_thresh = 0.05\n",
    "cmap = 'Reds';\n",
    "vmin=mask_thresh;\n",
    "vmax=0.5\n",
    "TickLabsize = 8\n",
    "textSize = 9\n",
    "\n",
    "# writer = pd.ExcelWriter(f'XGB SHAP values {Sheet_name}.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Iterate through each drug in SHAP_test\n",
    "for drg in SHAP_test.keys():\n",
    "    tbin_df = pd.DataFrame()\n",
    "    # Iterate through each time bin in SHAP_test for the current drug\n",
    "    for tbin in SHAP_test[drg].keys():\n",
    "        normalized_df = pd.DataFrame()\n",
    "        # Check if SHAP values are segmented by frequency\n",
    "        if len(list(SHAP_test[drg][tbin].keys())) == 1:\n",
    "            cbar_ttl = 'SHAP'\n",
    "            # If not segmented, normalize SHAP values directly\n",
    "            dfdf = SHAP_test[drg][tbin]    \n",
    "            MinMax_norm = (dfdf.values - dfdf.values.min(axis=1, keepdims=True)) / (dfdf.values.max(axis=1, keepdims=True) - dfdf.values.min(axis=1, keepdims=True))\n",
    "            normalized_df = pd.DataFrame(MinMax_norm, columns=feature_columns)     \n",
    "            normalized_df = pd.DataFrame(normalized_df.mean(axis = 0)).T\n",
    "        if len(list(SHAP_test[drg][tbin].keys())) > 1:\n",
    "            # If segmented, normalize SHAP values for each frequency and calculate weighted average if specified\n",
    "            freq_shap = pd.DataFrame()\n",
    "            for freq in SHAP_test[drg][tbin].keys():\n",
    "                col_names = dict_seg_features[freq]\n",
    "                dfdf = SHAP_test[drg][tbin][freq]   \n",
    "                MinMax_norm = (dfdf.values - dfdf.values.min(axis=1, keepdims=True)) / (dfdf.values.max(axis=1, keepdims=True) - dfdf.values.min(axis=1, keepdims=True))\n",
    "                freq_shap = pd.DataFrame(MinMax_norm, columns=col_names)\n",
    "                freq_shap = pd.DataFrame(freq_shap.mean(axis=0)).T\n",
    "                if normalize_to_accu:\n",
    "                    # If normalize_to_accu is True, weight SHAP values by accuracy\n",
    "                    cbar_ttl = 'Weighted SHAP'\n",
    "                    for index, row in averaged_accu.iterrows():\n",
    "                        if (row['DrgCmb'] == drg and\n",
    "                            row['tbin'] == tbin and\n",
    "                            row['freqBand'] == freq):\n",
    "                            val = row['TestAccuracy']                            \n",
    "                            freq_shap = freq_shap * val ## Multiply the (mean_accuracy - chance_lev accuracy) value to shap\n",
    "                else:\n",
    "                    cbar_ttl = 'SHAP'\n",
    "                            \n",
    "                normalized_df = pd.concat([normalized_df, freq_shap], axis=1)\n",
    "        tbin_df[tbin] = normalized_df.T\n",
    "\n",
    "    tbin_df.index.name = 'time_point'\n",
    "    tbin_df.reset_index(inplace=True)\n",
    "    norm_test_shap[drg] = tbin_df\n",
    "    rearr_shap = pd.DataFrame()\n",
    "    \n",
    "    # Rearrange normalized SHAP values into a single DataFrame\n",
    "    for freq in freqBands:\n",
    "        temp_df = norm_test_shap[drg][norm_test_shap[drg]['time_point'].isin(dict_seg_features[freq])]\n",
    "        temp_df = temp_df.drop(['time_point'], axis=1)\n",
    "        \n",
    "        temp_df.rename(columns=lambda x: x + f'_{freq}', inplace=True)\n",
    "        temp_df.reset_index(inplace=True)    \n",
    "        rearr_shap = pd.concat([rearr_shap, temp_df], axis=1)    \n",
    "        rearr_shap = rearr_shap.drop(['index'], axis=1)\n",
    "\n",
    "    # Remove columns with '10_min_' in the name for plotting\n",
    "    drop_cols_to_plt = [col for col in rearr_shap.columns if f'10_min_' in col]\n",
    "    shap2plt = rearr_shap.drop(drop_cols_to_plt, axis=1)           \n",
    "    mask = shap2plt[shap2plt > mask_thresh]\n",
    "    \n",
    "    # Generate labels for y-axis and x-axis\n",
    "    ylabels = [column.replace(f'_{freq}', '') for column in dict_seg_features[freq]] \n",
    "    ylabels = [string.replace('CA3', 'dCA3') for string in ylabels]\n",
    "    ylabels = [string.replace('dHC', 'dCA1') for string in ylabels]\n",
    "    xlabels = ['_'.join(column.split('_')[:-1]) for column in shap2plt.columns]\n",
    "\n",
    "    fig_names = f'{drg} {sheet_name} {cbar_ttl}'\n",
    "    figsize=(7,4);\n",
    "\n",
    "    f = figure(figsize=figsize)\n",
    "    ax = sns.heatmap(shap2plt, annot= False, fmt=\"\", vmin=vmin,  vmax=vmax,\n",
    "                     annot_kws={\"size\": 15, 'weight': 'bold', 'color':'k', \"ha\": 'center',\"va\": 'center'},                 \n",
    "                     cmap = cmap ,cbar_kws= {\"shrink\": 1, 'aspect':50},\n",
    "                     linewidths=0.5, linecolor='lightgray', mask=mask.isnull())\n",
    "    \n",
    "    ax.axvline(x=5, linewidth=0.5, color=\"k\")    \n",
    "    ax.axvline(x=10, linewidth=0.5, color=\"k\")\n",
    "    ax.axvline(x=15,linewidth=0.5, color=\"k\")\n",
    "    ax.axvline(x=20,linewidth=0.5, color=\"k\")\n",
    "    ax.axvline(x=25,linewidth=0.5, color=\"k\")\n",
    "    \n",
    "    \n",
    "    ax.axhline(y=4, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=8, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=12, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=16, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=20, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=24, linewidth=0.5, color=\"k\")    \n",
    "    ax.axhline(y=28, linewidth=0.5, color=\"k\")\n",
    "    \n",
    "    ax.text(1,-0.5,\"Delta\", size = textSize, weight = 'normal')    \n",
    "    ax.text(6,-0.5,\"Theta\", size = textSize, weight = 'normal')    \n",
    "    ax.text(11.5,-0.5,\"Beta\", size = textSize, weight = 'normal')\n",
    "    ax.text(15.5,-0.5,\"LoGamma\", size = textSize, weight = 'normal')\n",
    "    ax.text(20.2,-0.5,\"MiGamma\", size = textSize, weight = 'normal')\n",
    "    ax.text(25.5,-0.5,\"HiGamma\", size = textSize, weight = 'normal')\n",
    "    \n",
    "    ax.set_yticklabels(ylabels, rotation='horizontal',\n",
    "                       size = TickLabsize, weight = 'normal')\n",
    "    ax.set_xticklabels(xlabels, rotation=90, size = TickLabsize,\n",
    "                       weight = 'normal', horizontalalignment= 'center',\n",
    "                       verticalalignment=\"top\")\n",
    "    ax.set_title(fig_names, size = TickLabsize, weight = 'normal', pad = 30)\n",
    "    ax.collections[0].colorbar.set_label(cbar_ttl, weight = 'bold',\n",
    "                                         size = TickLabsize, rotation = 270,\n",
    "                                         labelpad = TickLabsize)\n",
    "\n",
    "    figName = f' {fig_names}.pdf' \n",
    "    figName2 = f' {fig_names}.jpg' \n",
    "    \n",
    "    if save_fig:\n",
    "        plt.rcParams['pdf.use14corefonts'] = True\n",
    "        plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "        plt.savefig(figName,  dpi = 300, bbox_inches='tight', transparent=True, metadata={'Creator': None})\n",
    "        plt.savefig(figName2,  dpi = 300, bbox_inches='tight', transparent=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "8c4bf203-e796-4464-bdbf-ccf86e2cc9c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eddabb1-31c0-4b5d-9bd4-292219e569e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
